"""
ETAPA 2: An√°lise de Sentimentos

CLI para analisar emo√ß√µes faciais nas cenas.
"""

import argparse
from pathlib import Path
import sys
import os

# Configurar encoding UTF-8 para evitar erros no Windows
if sys.platform == 'win32':
    os.environ['PYTHONIOENCODING'] = 'utf-8'
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from src.analyzers.emotion_analyzer import EmotionAnalyzer
from src.core.report_generator import ReportGenerator


def main():
    parser = argparse.ArgumentParser(
        description='Etapa 2: An√°lise de Sentimentos',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )

    parser.add_argument('--input-dir', '-i', default='output/cenas', help='Diret√≥rio com cenas')
    parser.add_argument('--output-dir', '-o', default='output/sentimentos', help='Diret√≥rio de sa√≠da')
    parser.add_argument('--confidence', '-c', type=float, default=0.5, help='Confian√ßa m√≠nima')
    parser.add_argument('--device', '-d', default='auto', choices=['auto', 'cuda', 'cpu'], help='Dispositivo')
    parser.add_argument('--no-scores', action='store_true', help='N√£o mostrar scores')
    # Nota: DeepFace usa RetinaFace para detec√ß√£o e seus pr√≥prios modelos de emo√ß√£o (baixados automaticamente)

    args = parser.parse_args()

    print("\n" + "="*60)
    print("ETAPA 2: ANALISE DE SENTIMENTOS")
    print("="*60 + "\n")

    # Criar analisador
    analyzer = EmotionAnalyzer(
        confidence_threshold=args.confidence,
        device=args.device
    )

    # Listar cenas
    input_dir = Path(args.input_dir)
    scenes = sorted(input_dir.glob("cena_*.mp4"))

    if not scenes:
        print(f"[ERRO] Nenhuma cena encontrada em {input_dir}")
        return

    print(f"[INFO] {len(scenes)} cenas encontradas\n")

    # Processar cada cena
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    all_results = []

    # Mapeamento de emo√ß√µes para emojis
    emotion_emojis = {
        'feliz': 'üòä',
        'triste': 'üò¢',
        'raiva': 'üò†',
        'surpreso': 'üò®',
        'neutro': 'üòê',
        'medo': 'üò∞',
        'nojo': 'ü§¢',
        'desprezo': 'üòí'
    }

    for idx, scene_path in enumerate(scenes, 1):
        scene_name = scene_path.stem
        output_path = output_dir / f"{scene_name}_sentimentos.mp4"

        print(f"\nüé¨ [{idx}/{len(scenes)}] Processando {scene_name}...")

        result = analyzer.process_scene(
            str(scene_path),
            str(output_path),
            show_scores=not args.no_scores
        )

        all_results.append(result)

        # Obter emoji da emo√ß√£o predominante
        emotion = result['dominant_emotion']
        emoji = emotion_emojis.get(emotion, 'üòê')

        # Estat√≠sticas da cena
        detection_rate = result['detection_rate']
        total_det = result['total_detections']
        max_people = result['max_people']

        print(f"   {emoji} Emo√ß√£o predominante: {emotion.upper()}")
        print(f"   üë• Pessoas detectadas: {total_det} detec√ß√µes | Taxa: {detection_rate:.1f}%")
        print(f"   üìä Max pessoas simult√¢neas: {max_people}")
        print(f"   ‚úÖ Salvo em: {output_path.name}")

    # Gerar relat√≥rio consolidado
    total_detections = sum(r['total_detections'] for r in all_results)

    report_path = output_dir / "relatorio_sentimentos.md"
    ReportGenerator.generate_emotion_report(
        {
            'total_detections': total_detections,
            'scenes': all_results
        },
        str(report_path)
    )

    # Calcular estat√≠sticas globais
    total_frames = sum(r['total_frames'] for r in all_results)
    frames_with_faces = sum(r['frames_with_faces'] for r in all_results)
    global_detection_rate = (frames_with_faces / total_frames * 100) if total_frames > 0 else 0

    # Distribui√ß√£o de emo√ß√µes
    emotion_dist = {}
    for result in all_results:
        for emotion, count in result['emotion_distribution'].items():
            emotion_dist[emotion] = emotion_dist.get(emotion, 0) + count

    # Emo√ß√£o mais comum
    most_common_emotion = max(emotion_dist, key=emotion_dist.get) if emotion_dist else 'neutro'
    emoji = emotion_emojis.get(most_common_emotion, 'üòê')

    print("\n" + "="*60)
    print("‚úÖ ETAPA 2 CONCLU√çDA COM SUCESSO!")
    print("="*60)
    print(f"\nüìä ESTAT√çSTICAS GLOBAIS:")
    print(f"   ‚Ä¢ Total de cenas processadas: {len(scenes)}")
    print(f"   ‚Ä¢ Total de frames analisados: {total_frames:,}")
    print(f"   ‚Ä¢ Total de detec√ß√µes: {total_detections:,}")
    print(f"   ‚Ä¢ Taxa de detec√ß√£o global: {global_detection_rate:.1f}%")
    print(f"   ‚Ä¢ Emo√ß√£o mais comum: {emoji} {most_common_emotion.upper()} ({emotion_dist.get(most_common_emotion, 0)} detec√ß√µes)")
    print(f"\nüìÑ Relat√≥rio completo salvo em:")
    print(f"   {report_path}")
    print("="*60 + "\n")


if __name__ == '__main__':
    main()
